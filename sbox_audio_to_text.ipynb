{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 main steps \n",
    "# 1 - Google API (cost considerations)\n",
    "# 2 - HuggingFace\n",
    "# May requires translation, cutting podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3path = r\"C:\\Users\\lgarzia\\Documents\\GitHub\\topic_extractions\\podcasts\\winter_break.mp3\"\n",
    "# 25 second long mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.askpython.com/python/environment-variables-in-python\n",
    "import os\n",
    "e = os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLUSERSPROFILE',\n",
       " 'APPDATA',\n",
       " 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL',\n",
       " 'CHROME_CRASHPAD_PIPE_NAME',\n",
       " 'CLICOLOR',\n",
       " 'CLICOLOR_FORCE',\n",
       " 'CLOUDSDK_METRICS_ENVIRONMENT',\n",
       " 'CLOUDSDK_METRICS_ENVIRONMENT_VERSION',\n",
       " 'CLOUDSDK_PYTHON',\n",
       " 'COMMONPROGRAMFILES',\n",
       " 'COMMONPROGRAMFILES(X86)',\n",
       " 'COMMONPROGRAMW6432',\n",
       " 'COMPUTERNAME',\n",
       " 'COMSPEC',\n",
       " 'CUDA_PATH',\n",
       " 'CUDA_PATH_V11_3',\n",
       " 'CUDA_PATH_V11_5',\n",
       " 'DRIVERDATA',\n",
       " 'ELECTRON_NO_ATTACH_CONSOLE',\n",
       " 'ELECTRON_RUN_AS_NODE',\n",
       " 'FORCE_COLOR',\n",
       " 'FPS_BROWSER_APP_PROFILE_STRING',\n",
       " 'FPS_BROWSER_USER_PROFILE_STRING',\n",
       " 'GIT_LFS_PATH',\n",
       " 'GIT_PAGER',\n",
       " 'HADOOP_HOME',\n",
       " 'HOMEDRIVE',\n",
       " 'HOMEPATH',\n",
       " 'JAVA_HOME',\n",
       " 'JPY_INTERRUPT_EVENT',\n",
       " 'LOCALAPPDATA',\n",
       " 'LOGONSERVER',\n",
       " 'MPLBACKEND',\n",
       " 'NUMBER_OF_PROCESSORS',\n",
       " 'NVCUDASAMPLES11_3_ROOT',\n",
       " 'NVCUDASAMPLES11_5_ROOT',\n",
       " 'NVCUDASAMPLES_ROOT',\n",
       " 'NVTOOLSEXT_PATH',\n",
       " 'ONEDRIVE',\n",
       " 'ORIGINAL_XDG_CURRENT_DESKTOP',\n",
       " 'OS',\n",
       " 'PAGER',\n",
       " 'PATH',\n",
       " 'PATHEXT',\n",
       " 'PROCESSOR_ARCHITECTURE',\n",
       " 'PROCESSOR_IDENTIFIER',\n",
       " 'PROCESSOR_LEVEL',\n",
       " 'PROCESSOR_REVISION',\n",
       " 'PROGRAMDATA',\n",
       " 'PROGRAMFILES',\n",
       " 'PROGRAMFILES(X86)',\n",
       " 'PROGRAMW6432',\n",
       " 'PROMPT',\n",
       " 'PSMODULEPATH',\n",
       " 'PUBLIC',\n",
       " 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING',\n",
       " 'PYDEVD_USE_FRAME_EVAL',\n",
       " 'PYTHONIOENCODING',\n",
       " 'PYTHONUNBUFFERED',\n",
       " 'SESSIONNAME',\n",
       " 'SPARK_HOME',\n",
       " 'SYSTEMDRIVE',\n",
       " 'SYSTEMROOT',\n",
       " 'TEMP',\n",
       " 'TERM',\n",
       " 'TMP',\n",
       " 'USERDOMAIN',\n",
       " 'USERDOMAIN_ROAMINGPROFILE',\n",
       " 'USERNAME',\n",
       " 'USERPROFILE',\n",
       " 'VIRTUAL_ENV',\n",
       " 'VIRTUAL_ENV_PROMPT',\n",
       " 'VS140COMNTOOLS',\n",
       " 'VSCODE_AMD_ENTRYPOINT',\n",
       " 'VSCODE_CLI',\n",
       " 'VSCODE_CODE_CACHE_PATH',\n",
       " 'VSCODE_CWD',\n",
       " 'VSCODE_HANDLES_UNCAUGHT_ERRORS',\n",
       " 'VSCODE_IPC_HOOK',\n",
       " 'VSCODE_L10N_BUNDLE_LOCATION',\n",
       " 'VSCODE_NLS_CONFIG',\n",
       " 'VSCODE_PID',\n",
       " 'WINDIR',\n",
       " 'ZES_ENABLE_SYSMAN',\n",
       " '_OLD_VIRTUAL_PATH',\n",
       " '_OLD_VIRTUAL_PROMPT']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(e.__dict__['_data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r\"C:\\Users\\lgarzia\\Documents\\GitHub\\GCP_100Days\\speech_to_text\\LG_SpeechText_Credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "\n",
    "def sample_recognize(storage_uri):\n",
    "    \"\"\"\n",
    "    Performs synchronous speech recognition on an audio file\n",
    "\n",
    "    Args:\n",
    "      storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.mp3'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 44100\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.MP3\n",
    "    config = {\n",
    "        \"language_code\": language_code,\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"encoding\": encoding,\n",
    "    }\n",
    "    audio = {\"uri\": storage_uri}\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/speech-to-text/docs/samples/speech-quickstart-beta\n",
    "def sample_recognize(storage_uri):\n",
    "    \"\"\"\n",
    "    Performs synchronous speech recognition on an audio file\n",
    "\n",
    "    Args:\n",
    "      storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.mp3'\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 44100\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.MP3\n",
    "    config = {\n",
    "        \"language_code\": language_code,\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"encoding\": encoding,\n",
    "    }\n",
    "    audio = {\"uri\": storage_uri}\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_uri =  r\"gs://advance-anvil-169016-audio-files/winter_break.mp3\"\n",
    "response = sample_recognize(storage_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[alternatives {\n",
       "  transcript: \"hey everyone thank you so much for listening to Google Cloud Reader will be taking a break as we get ready for 2023 and all that it\\'s got in store for us will be back in January and until then we hope you get a chance to spend some time doing what you love most thanks for listening see you next time\"\n",
       "  confidence: 0.969436884\n",
       "}\n",
       "result_end_time {\n",
       "  seconds: 22\n",
       "  nanos: 340000000\n",
       "}\n",
       "language_code: \"en-us\"\n",
       "]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: hey everyone thank you so much for listening to Google Cloud Reader will be taking a break as we get ready for 2023 and all that it's got in store for us will be back in January and until then we hope you get a chance to spend some time doing what you love most thanks for listening see you next time\n"
     ]
    }
   ],
   "source": [
    "for result in response.results:\n",
    "    # First alternative is the most probable result\n",
    "    alternative = result.alternatives[0]\n",
    "    print(\"Transcript: {}\".format(alternative.transcript))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does open source pretrained models work as effectively,,, not tech or buzz words here, but a good starting place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "API_TOKEN = Path(r'.\\artifacts\\tokens\\hugging_face_api_token.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3path = r\"C:\\Users\\lgarzia\\Documents\\GitHub\\topic_extractions\\podcasts\\winter_break.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/wav2vec2-base-960h\"\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "data = query(mp3path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"HAY EVERY ONE THANK YOU SO MUCH FOR LISTENING TO GUGGLECLOUD READER WE'LL BE TAKING A BRAG AS WE GET READY FOR TWENTY TWENTY THREE AND ALL THAT IT'S GOT IN STORE FOR US WE'LL BE BACK IN JANUARY AND UNTIL THEN WE HOPE YOU GET A CHANCE TO SPEND SOME TIME DOING WHAT YOU LOVE MOST THANKS FOR LISTENING SING NEXT TIME\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"say next time i every one think you so much for listening to grigal cloud reader we'll be taking a brig as we get ready for twenty twenty three and all that it's got in store for us will we back in january and until then we hope you get a chance to spend some doing what you love most thanks for listening say next time say next time say next time say next time say next time say next time\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/s2t-small-librispeech-asr\"\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "data = query(mp3path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Hey jeder, vielen Dank und bis dahin wird es Ihnen im Januar sehr Zeit sein, alles zu tun, was Sie beim nächsten Mal in Ordnung sind.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/s2t-wav2vec2-large-en-de\"\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "data = query(mp3path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50c2f3fdaff21cf524066e6f7d306be0b9f081a5cbf5acb3eba5a76347fee337"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
